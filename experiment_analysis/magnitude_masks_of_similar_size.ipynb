{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading region bounding boxes for computing carbon emissions region, this may take a moment...\n",
      " 454/454... rate=447.43 Hz, eta=0:00:00, total=0:00:01, wall=13:14 CETT\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "from model_bert import BertForSequenceClassification\n",
    "import torch.nn.utils.prune as prune\n",
    "from find_global_weight_mask import prune_model, L1UnstructuredInvert\n",
    "\n",
    "\n",
    "\n",
    "def load_mask_data(experiments_path):\n",
    "    mask_data = {}\n",
    "    for task_dir in experiments_path.iterdir():\n",
    "        mask_data[task_dir.stem] = {}\n",
    "        for seed_dir in task_dir.iterdir():\n",
    "            mask = torch.load(seed_dir / \"magnitude_mask.p\")\n",
    "            mask_data[task_dir.stem][seed_dir.stem] = mask\n",
    "    return mask_data\n",
    "def load_head_data(experiments_path):\n",
    "    head_data = {}\n",
    "    for task_dir in experiments_path.iterdir():\n",
    "        head_data[task_dir.stem] = {}\n",
    "        for seed_dir in task_dir.iterdir():\n",
    "            head_mask = np.load(seed_dir / \"head_mask.npy\")\n",
    "            head_data[task_dir.stem][seed_dir.stem] = {\n",
    "                \"head_mask\": head_mask,\n",
    "            }\n",
    "    return head_data\n",
    "def load_mlp_data(experiments_path):\n",
    "    mlp_data = {}\n",
    "    for task_dir in experiments_path.iterdir():\n",
    "        mlp_data[task_dir.stem] = {}\n",
    "        for seed_dir in task_dir.iterdir():\n",
    "            mlp_mask = np.load(seed_dir / \"mlp_mask.npy\")\n",
    "            mlp_importance = np.load(seed_dir / \"mlp_importance.npy\")\n",
    "            mlp_data[task_dir.stem][seed_dir.stem] = {\n",
    "                \"mlp_mask\": mlp_mask,\n",
    "                \"mlp_importance\": mlp_importance\n",
    "            }\n",
    "    return mlp_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = pathlib.Path(\"../masks/heads_mlps\")\n",
    "heads = load_head_data(experiments_path)\n",
    "experiments_path = pathlib.Path(\"../masks/heads_mlps\")\n",
    "mlps = load_mlp_data(experiments_path)\n",
    "\n",
    "models_path = pathlib.Path(\"../models/finetuned\")\n",
    "global_masks_path = pathlib.Path(\"../masks/global/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import prune\n",
    "def heads_to_prune(model):\n",
    "    parameters_to_prune = []\n",
    "    for layer in model.bert.encoder.layer:\n",
    "        parameters = [\n",
    "            (layer.attention.self.key, 'weight'),\n",
    "            (layer.attention.self.key, 'bias'),\n",
    "            (layer.attention.self.query, 'weight'),\n",
    "            (layer.attention.self.query, 'bias'),\n",
    "            (layer.attention.self.value, 'weight'),\n",
    "            (layer.attention.self.value, 'bias'),\n",
    "            (layer.attention.output.dense, 'weight'),\n",
    "            (layer.attention.output.dense, 'bias'),\n",
    "        ]\n",
    "        parameters_to_prune.extend(parameters)\n",
    "    return parameters_to_prune\n",
    "def mlps_to_prune(model):\n",
    "    parameters_to_prune = []\n",
    "    for layer in model.bert.encoder.layer:\n",
    "        parameters = [\n",
    "            (layer.intermediate.dense, 'weight'),\n",
    "            (layer.intermediate.dense, 'bias'),\n",
    "            (layer.output.dense, 'weight'),\n",
    "            #(layer.output.dense, 'bias'), Since we don't prune this in importance based pruning.\n",
    "        ]\n",
    "        parameters_to_prune.extend(parameters)\n",
    "    return parameters_to_prune\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heads: 0.0 MLPS: 0.0\n",
      "Heads: 0.0 MLPS: 0.0\n",
      "Heads: 1.0 MLPS: 0.0\n",
      "Heads: 0.0 MLPS: 0.0\n",
      "Heads: 0.0 MLPS: 0.0\n",
      "Heads: 0.5625 MLPS: 0.75\n",
      "Heads: 0.6111111111111112 MLPS: 0.6666666666666666\n",
      "Heads: 0.6597222222222222 MLPS: 0.9166666666666666\n",
      "Heads: 0.5625 MLPS: 0.75\n",
      "Heads: 0.7083333333333334 MLPS: 0.75\n",
      "Heads: 0.6111111111111112 MLPS: 0.5833333333333334\n",
      "Heads: 0.6597222222222222 MLPS: 0.75\n",
      "Heads: 0.6597222222222222 MLPS: 0.75\n",
      "Heads: 0.7083333333333334 MLPS: 0.75\n",
      "Heads: 0.6597222222222222 MLPS: 0.6666666666666666\n",
      "Heads: 0.7083333333333334 MLPS: 0.75\n",
      "Heads: 0.4652777777777778 MLPS: 0.6666666666666666\n",
      "Heads: 0.6111111111111112 MLPS: 0.75\n",
      "Heads: 0.4652777777777778 MLPS: 0.75\n",
      "Heads: 0.4652777777777778 MLPS: 0.6666666666666666\n",
      "Heads: 0.5138888888888888 MLPS: 0.6666666666666666\n",
      "Heads: 0.125 MLPS: 0.9166666666666666\n",
      "Heads: 0.5138888888888888 MLPS: 0.5833333333333334\n",
      "Heads: 0.8055555555555556 MLPS: 0.9166666666666666\n",
      "Heads: 0.6111111111111112 MLPS: 0.75\n",
      "Heads: 0.4166666666666667 MLPS: 0.75\n",
      "Heads: 0.6111111111111112 MLPS: 0.6666666666666666\n",
      "Heads: 0.4652777777777778 MLPS: 0.6666666666666666\n",
      "Heads: 0.5138888888888888 MLPS: 0.5833333333333334\n",
      "Heads: 0.3194444444444444 MLPS: 0.5833333333333334\n",
      "Heads: 0.6111111111111112 MLPS: 0.4166666666666667\n",
      "Heads: 0.5138888888888888 MLPS: 0.6666666666666666\n",
      "Heads: 0.5625 MLPS: 0.6666666666666666\n",
      "Heads: 0.5138888888888888 MLPS: 0.5833333333333334\n",
      "Heads: 0.4652777777777778 MLPS: 0.75\n",
      "Heads: 0.7083333333333334 MLPS: 0.9166666666666666\n",
      "Heads: 0.6597222222222222 MLPS: 0.9166666666666666\n",
      "Heads: 0.8055555555555556 MLPS: 0.8333333333333334\n",
      "Heads: 0.5625 MLPS: 1.0\n",
      "Heads: 0.4652777777777778 MLPS: 0.8333333333333334\n",
      "Heads: 0.5138888888888888 MLPS: 0.75\n",
      "Heads: 0.5625 MLPS: 0.75\n",
      "Heads: 0.6111111111111112 MLPS: 0.75\n",
      "Heads: 0.6597222222222222 MLPS: 0.75\n",
      "Heads: 0.6111111111111112 MLPS: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(13)\n",
    "for task in heads:\n",
    "    for seed in heads[task]:\n",
    "        print(task, seed)\n",
    "        heads_pct = heads[task][seed][\"head_mask\"].sum() / heads[task][seed][\"head_mask\"].size\n",
    "        mlps_pct  = mlps[task][seed][\"mlp_mask\"].sum() / mlps[task][seed][\"mlp_mask\"].size\n",
    "        heads_pct = heads_pct.item()\n",
    "        mlps_pct = mlps_pct.item()\n",
    "        print(f\"Good Heads: {heads_pct} MLPS: {mlps_pct}\")\n",
    "        model     = BertForSequenceClassification.from_pretrained(str(models_path / task / seed ))\n",
    "        heads_prune = heads_to_prune(model)\n",
    "        mlps_prune = mlps_to_prune(model)\n",
    "        prune.global_unstructured(\n",
    "            heads_prune,\n",
    "            pruning_method=prune.L1Unstructured,\n",
    "            amount=1 - heads_pct,\n",
    "        )\n",
    "        prune.global_unstructured(\n",
    "            mlps_prune,\n",
    "            pruning_method=prune.L1Unstructured,\n",
    "            amount=1 - mlps_pct,\n",
    "        )\n",
    "        global_mag_masks = {k:v for k, v in model.named_buffers()}\n",
    "        #torch.save(global_mag_masks, str(global_masks_path/task/seed/\"magnitude_mimic.pt\"))\n",
    "        \n",
    "        print(f\"Good Heads: {heads_pct} MLPS: {mlps_pct}\")\n",
    "        model     = BertForSequenceClassification.from_pretrained(str(models_path / task / seed ))\n",
    "        heads_prune = heads_to_prune(model)\n",
    "        mlps_prune = mlps_to_prune(model)\n",
    "        prune.global_unstructured(\n",
    "            heads_prune,\n",
    "            pruning_method=L1UnstructuredInvert,\n",
    "            amount=1 - heads_pct,\n",
    "        )\n",
    "        prune.global_unstructured(\n",
    "            mlps_prune,\n",
    "            pruning_method=L1UnstructuredInvert,\n",
    "            amount=1 - mlps_pct,\n",
    "        )\n",
    "        global_mag_masks = {k:v for k, v in model.named_buffers()}\n",
    "        #torch.save(global_mag_masks, str(global_masks_path/task/seed/\"bad_mimic.pt\"))\n",
    "        \n",
    "        \n",
    "        model     = BertForSequenceClassification.from_pretrained(str(models_path / task / seed ))\n",
    "        heads_prune = heads_to_prune(model)\n",
    "        mlps_prune = mlps_to_prune(model)\n",
    "        prune.global_unstructured(\n",
    "            heads_prune,\n",
    "            pruning_method=prune.RandomUnstructured,\n",
    "            amount=1 - heads_pct,\n",
    "        )\n",
    "        prune.global_unstructured(\n",
    "            mlps_prune,\n",
    "            pruning_method=prune.RandomUnstructured,\n",
    "            amount=1 - mlps_pct,\n",
    "        )\n",
    "        global_mag_masks = {k:v for k, v in model.named_buffers()}\n",
    "        #torch.save(global_mag_masks, str(global_masks_path/task/seed/\"random_mimic.pt\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bad masks of equal size as \"good\" magnitude masks, sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_global_mask_data(experiments_path):\n",
    "    mask_data = {}\n",
    "    for task_dir in experiments_path.iterdir():\n",
    "        mask_data[task_dir.stem] = {}\n",
    "        for seed_dir in task_dir.iterdir():\n",
    "            mask = torch.load(seed_dir / \"magnitude_mask.p\")\n",
    "            mask_data[task_dir.stem][seed_dir.stem] = mask\n",
    "    return mask_data\n",
    "\n",
    "global_masks_path = pathlib.Path(\"../masks/global/\")\n",
    "models_dir = pathlib.Path(\"../models/finetuned/\")\n",
    "global_masks = load_global_mask_data(global_masks_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in global_masks:\n",
    "    for seed in global_masks[task]:\n",
    "        good_mask = global_masks[task][seed]\n",
    "        total_masked = sum([(1-v).sum() for v in good_mask.values()])\n",
    "        total_elements = sum([v.numel() for v in good_mask.values()])\n",
    "        amount = total_masked/total_elements\n",
    "        model = BertForSequenceClassification.from_pretrained(str(models_dir / task / seed))\n",
    "        new_mask = prune_model(model, amount=amount.item(), mode=L1UnstructuredInvert)\n",
    "        torch.save(new_mask, str(global_masks_path/task/seed/\"bad_mask.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_global_mask_data(experiments_path):\n",
    "    mask_data = {}\n",
    "    for task_dir in experiments_path.iterdir():\n",
    "        mask_data[task_dir.stem] = {}\n",
    "        for seed_dir in task_dir.iterdir():\n",
    "            mask = torch.load(seed_dir / \"magnitude_mask.p\")\n",
    "            mask_data[task_dir.stem][seed_dir.stem] = mask\n",
    "    return mask_data\n",
    "\n",
    "def load_global_mask_data_1(experiments_path):\n",
    "    mask_data = {}\n",
    "    for task_dir in experiments_path.iterdir():\n",
    "        mask_data[task_dir.stem] = {}\n",
    "        for seed_dir in task_dir.iterdir():\n",
    "            mask = torch.load(seed_dir / \"magnitude_mimic.pt\")\n",
    "            mask_data[task_dir.stem][seed_dir.stem] = mask\n",
    "    return mask_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "do = load_global_mask_data(global_masks_path)\n",
    "dm = load_global_mask_data_1(global_masks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "origgg = []\n",
    "mimiccc = []\n",
    "for task in do:\n",
    "    for seed in do[task]:\n",
    "        orig = do[task][seed]\n",
    "        mimic = dm[task][seed]\n",
    "        pruned_o = sum([(1-v).sum() for v in orig.values()]) / sum([v.numel() for v in orig.values()])\n",
    "        pruned_m = sum([(1-v).sum() for v in mimic.values()]) / sum([v.numel() for v in mimic.values()])\n",
    "        #print(f\"Pruned o - {pruned_o} Pruned m - {pruned_m}\")\n",
    "        origgg.append(pruned_o)\n",
    "        mimiccc.append(pruned_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4816)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(origgg) / len(origgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3901)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mimiccc) / len(mimiccc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
