{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src\")\n",
    "from model_bert import BertForSequenceClassification\n",
    "from config_bert import BertConfig\n",
    "from run_glue import load_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dir = pathlib.Path(\"../masks/global/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = {}\n",
    "for task_dir in global_dir.iterdir():\n",
    "    task = task_dir.stem\n",
    "    masks[task] = {}\n",
    "    for seed_dir in task_dir.iterdir():\n",
    "        seed = seed_dir.stem\n",
    "        masks[task][seed] = {}\n",
    "        masks[task][seed][\"magnitude\"] = torch.load(str(seed_dir / \"magnitude_mask.p\"))\n",
    "        masks[task][seed][\"bad\"] = torch.load(str(seed_dir/\"bad_mask.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = pathlib.Path(\"../models/finetuned/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WNLI seed_71\n",
      "tensor(3.9156)\n",
      "WNLI seed_1337\n",
      "tensor(12.6881)\n",
      "WNLI seed_86\n",
      "tensor(1.1837)\n",
      "WNLI seed_42\n",
      "tensor(4.5969)\n",
      "WNLI seed_166\n",
      "tensor(12.6880)\n",
      "MRPC seed_71\n",
      "tensor(3.3142)\n",
      "MRPC seed_1337\n",
      "tensor(4.2456)\n",
      "MRPC seed_86\n",
      "tensor(3.0404)\n",
      "MRPC seed_42\n",
      "tensor(3.0405)\n",
      "MRPC seed_166\n",
      "tensor(3.3142)\n",
      "MNLI seed_71\n",
      "tensor(3.9148)\n",
      "MNLI seed_1337\n",
      "tensor(3.9147)\n",
      "MNLI seed_86\n",
      "tensor(3.9147)\n",
      "MNLI seed_42\n",
      "tensor(3.9147)\n",
      "MNLI seed_166\n",
      "tensor(3.9145)\n",
      "QQP seed_71\n",
      "tensor(4.2449)\n",
      "QQP seed_1337\n",
      "tensor(4.5960)\n",
      "QQP seed_86\n",
      "tensor(4.2444)\n",
      "QQP seed_42\n",
      "tensor(4.5960)\n",
      "QQP seed_166\n",
      "tensor(4.2446)\n",
      "RTE seed_71\n",
      "tensor(4.2456)\n",
      "RTE seed_1337\n",
      "tensor(3.9155)\n",
      "RTE seed_86\n",
      "tensor(3.6055)\n",
      "RTE seed_42\n",
      "tensor(3.3142)\n",
      "RTE seed_166\n",
      "tensor(3.6055)\n",
      "SST-2 seed_71\n",
      "tensor(4.9707)\n",
      "SST-2 seed_1337\n",
      "tensor(4.9707)\n",
      "SST-2 seed_86\n",
      "tensor(5.3685)\n",
      "SST-2 seed_42\n",
      "tensor(4.9707)\n",
      "SST-2 seed_166\n",
      "tensor(4.9707)\n",
      "STS-B seed_71\n",
      "tensor(3.6055)\n",
      "STS-B seed_1337\n",
      "tensor(4.2456)\n",
      "STS-B seed_86\n",
      "tensor(3.9155)\n",
      "STS-B seed_42\n",
      "tensor(4.2455)\n",
      "STS-B seed_166\n",
      "tensor(4.2456)\n",
      "CoLA seed_71\n",
      "tensor(2.5413)\n",
      "CoLA seed_1337\n",
      "tensor(2.0994)\n",
      "CoLA seed_86\n",
      "tensor(2.3137)\n",
      "CoLA seed_42\n",
      "tensor(3.6055)\n",
      "CoLA seed_166\n",
      "tensor(3.6055)\n",
      "QNLI seed_71\n",
      "tensor(3.9153)\n",
      "QNLI seed_1337\n",
      "tensor(3.6052)\n",
      "QNLI seed_86\n",
      "tensor(3.6052)\n",
      "QNLI seed_42\n",
      "tensor(3.6052)\n",
      "QNLI seed_166\n",
      "tensor(3.9153)\n"
     ]
    }
   ],
   "source": [
    "scaling_factors = {}\n",
    "\n",
    "for task in masks:\n",
    "    scaling_factors[task] = {}\n",
    "    for seed in masks[task]:\n",
    "        good_masks = masks[task][seed][\"magnitude\"]\n",
    "        bad_masks = masks[task][seed][\"bad\"]\n",
    "        model = BertForSequenceClassification.from_pretrained(str(model_dir / task / seed))\n",
    "        state_dict = model.state_dict()\n",
    "        good_weight_sum = 0\n",
    "        good_weight_total = 0\n",
    "        for mask_name, mask in good_masks.items():\n",
    "            component = state_dict[mask_name[:-5]]\n",
    "            good_weight_sum += (component * mask).abs().sum()\n",
    "            good_weight_total += mask.numel()\n",
    "        good_weight_mean = good_weight_sum / good_weight_total\n",
    "        bad_weight_sum = 0\n",
    "        bad_weight_total = 0\n",
    "        for mask_name, mask in bad_masks.items():\n",
    "            component = state_dict[mask_name[:-5]]\n",
    "            bad_weight_sum += (component * mask).abs().sum()\n",
    "            bad_weight_total += mask.numel()\n",
    "        bad_weight_mean = bad_weight_sum / bad_weight_total\n",
    "        scaling_factor = good_weight_mean/bad_weight_mean\n",
    "        print(task, seed)\n",
    "        print(scaling_factor)\n",
    "        scaling_factors[task][seed] = scaling_factor.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WNLI': {'seed_71': 3.915574312210083,\n",
       "  'seed_1337': 12.68806266784668,\n",
       "  'seed_86': 1.183749794960022,\n",
       "  'seed_42': 4.596926212310791,\n",
       "  'seed_166': 12.687975883483887},\n",
       " 'MRPC': {'seed_71': 3.3142013549804688,\n",
       "  'seed_1337': 4.245562553405762,\n",
       "  'seed_86': 3.0404460430145264,\n",
       "  'seed_42': 3.0404586791992188,\n",
       "  'seed_166': 3.3141989707946777},\n",
       " 'MNLI': {'seed_71': 3.9147980213165283,\n",
       "  'seed_1337': 3.914726734161377,\n",
       "  'seed_86': 3.9146506786346436,\n",
       "  'seed_42': 3.9146640300750732,\n",
       "  'seed_166': 3.914477586746216},\n",
       " 'QQP': {'seed_71': 4.244863033294678,\n",
       "  'seed_1337': 4.5959672927856445,\n",
       "  'seed_86': 4.244410991668701,\n",
       "  'seed_42': 4.5959577560424805,\n",
       "  'seed_166': 4.24460506439209},\n",
       " 'RTE': {'seed_71': 4.245597839355469,\n",
       "  'seed_1337': 3.915539026260376,\n",
       "  'seed_86': 3.605501890182495,\n",
       "  'seed_42': 3.3142037391662598,\n",
       "  'seed_166': 3.6055095195770264},\n",
       " 'SST-2': {'seed_71': 4.970656871795654,\n",
       "  'seed_1337': 4.970679759979248,\n",
       "  'seed_86': 5.368537425994873,\n",
       "  'seed_42': 4.970706462860107,\n",
       "  'seed_166': 4.9707489013671875},\n",
       " 'STS-B': {'seed_71': 3.6054959297180176,\n",
       "  'seed_1337': 4.245572090148926,\n",
       "  'seed_86': 3.915526866912842,\n",
       "  'seed_42': 4.245546340942383,\n",
       "  'seed_166': 4.2455878257751465},\n",
       " 'CoLA': {'seed_71': 2.541257858276367,\n",
       "  'seed_1337': 2.099383592605591,\n",
       "  'seed_86': 2.313671350479126,\n",
       "  'seed_42': 3.605506658554077,\n",
       "  'seed_166': 3.605530261993408},\n",
       " 'QNLI': {'seed_71': 3.9152510166168213,\n",
       "  'seed_1337': 3.605203628540039,\n",
       "  'seed_86': 3.6052112579345703,\n",
       "  'seed_42': 3.605221748352051,\n",
       "  'seed_166': 3.9152534008026123}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaling_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
